{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko2MJeQbbmRj",
        "outputId": "406ff0bb-906d-4c66-be9b-38a51e7577f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  214M  100  214M    0     0   136M      0  0:00:01  0:00:01 --:--:--  243M\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o /content/archive.zip https://www.kaggle.com/api/v1/datasets/download/kmader/electron-microscopy-3d-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_0yjvZZMPLQ",
        "outputId": "3df13d16-074e-4344-96ad-7717097b2912"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/archive.zip\n",
            "  inflating: testing.tif             \n",
            "  inflating: testing_groundtruth.tif  \n",
            "  inflating: training.tif            \n",
            "  inflating: training_groundtruth.tif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "# Load data function\n",
        "def load_data():\n",
        "    # Load the TIFF images\n",
        "    train_images = tifffile.imread('/content/training.tif')\n",
        "    train_labels = tifffile.imread('/content/training_groundtruth.tif')\n",
        "    test_images = tifffile.imread('/content/testing.tif')\n",
        "    test_labels = tifffile.imread('/content/testing_groundtruth.tif')\n",
        "\n",
        "    # Normalize the images to [0, 1]\n",
        "    train_images = train_images.astype(np.float32) / np.max(train_images)\n",
        "    test_images = test_images.astype(np.float32) / np.max(test_images)\n",
        "\n",
        "    # Ensure labels are binary (0 or 1)\n",
        "    train_labels = (train_labels > 0).astype(np.float32)\n",
        "    test_labels = (test_labels > 0).astype(np.float32)\n",
        "\n",
        "    # Add channel dimension for compatibility with Keras (depth, height, width, channels)\n",
        "    train_images = np.expand_dims(train_images, axis=-1)\n",
        "    train_labels = np.expand_dims(train_labels, axis=-1)\n",
        "    test_images = np.expand_dims(test_images, axis=-1)\n",
        "    test_labels = np.expand_dims(test_labels, axis=-1)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "# Load the data\n",
        "train_images, train_labels, test_images, test_labels = load_data()\n",
        "\n",
        "# Resize images to (256, 256) and add a channel dimension for grayscale (1 channel)\n",
        "train_images = tf.image.resize(train_images, (256, 256))\n",
        "train_labels = tf.image.resize(train_labels, (256, 256))\n",
        "test_images = tf.image.resize(test_images, (256, 256))\n",
        "test_labels = tf.image.resize(test_labels, (256, 256))\n",
        "\n",
        "train_images = np.expand_dims(train_images, axis=-1)  # Adds the channel dimension\n",
        "test_images = np.expand_dims(test_images, axis=-1)  # Adds the channel dimension\n",
        "\n",
        "# Ensure labels are clipped between 0 and 1\n",
        "train_labels = np.clip(train_labels, 0, 1)\n",
        "test_labels = np.clip(test_labels, 0, 1)\n",
        "\n",
        "# Check if the shapes are now correct\n",
        "print(train_images.shape)  # Should be (num_samples, 256, 256, 1)\n",
        "print(test_images.shape)   # Should be (num_samples, 256, 256, 1)\n",
        "print(train_labels.shape)  # Should be (num_samples, 256, 256, 1)\n",
        "print(test_labels.shape)   # Should be (num_samples, 256, 256, 1)\n",
        "\n",
        "# Define the 2D U-Net model architecture\n",
        "def unet_2d(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoding path\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    up6 = concatenate([up6, conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    up7 = concatenate([up7, conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    up8 = concatenate([up8, conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    up9 = concatenate([up9, conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# Define input shape and initialize the model\n",
        "input_shape = (256, 256, 1)  # (height, width, channels)\n",
        "model = unet_2d(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=BinaryCrossentropy(), metrics=[Accuracy()])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    epochs=10,\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "# Evaluate on the test set\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Predict on test images\n",
        "predicted_labels = model.predict(test_images)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "# Save each slice as a frame in a GIF\n",
        "frames = []\n",
        "for i in range(predicted_labels.shape[0]):  # Loop through the images in the batch\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(predicted_labels[i, :, :, 0], cmap='gray')  # Adjust the indices based on shape\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Save frame to a file-like object for creating the GIF\n",
        "    fig.canvas.draw()\n",
        "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
        "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "    frames.append(frame)\n",
        "    plt.close(fig)\n",
        "\n",
        "# Create a GIF\n",
        "gif_path = 'segmentation_results.gif'\n",
        "imageio.mimsave(gif_path, frames, fps=5)\n",
        "\n",
        "print(f\"GIF saved at: {gif_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqruOMw9Xb_m",
        "outputId": "ca42ea81-486d-4964-e112-c3269e49fa2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 256, 256, 1, 1)\n",
            "(165, 256, 256, 1, 1)\n",
            "(165, 256, 256, 1)\n",
            "(165, 256, 256, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 0.5266 - val_accuracy: 0.0000e+00 - val_loss: 0.2128\n",
            "Epoch 2/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.2193 - val_accuracy: 0.0000e+00 - val_loss: 0.2074\n",
            "Epoch 3/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 0.1931 - val_accuracy: 0.0000e+00 - val_loss: 0.2088\n",
            "Epoch 4/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 0.1741 - val_accuracy: 0.0000e+00 - val_loss: 0.2183\n",
            "Epoch 5/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 0.1323 - val_accuracy: 0.0000e+00 - val_loss: 0.1588\n",
            "Epoch 6/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.0000e+00 - loss: 0.0964 - val_accuracy: 0.0000e+00 - val_loss: 0.1699\n",
            "Epoch 7/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0814 - val_accuracy: 0.0000e+00 - val_loss: 0.2866\n",
            "Epoch 8/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0708 - val_accuracy: 0.0000e+00 - val_loss: 0.2058\n",
            "Epoch 9/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0588 - val_accuracy: 0.0000e+00 - val_loss: 0.2513\n",
            "Epoch 10/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 0.0447 - val_accuracy: 0.0000e+00 - val_loss: 0.2795\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.0000e+00 - loss: 0.3365\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-81191cc829d1>:142: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use buffer_rgba instead.\n",
            "  frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF saved at: segmentation_results.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Segmanation.keras\")"
      ],
      "metadata": {
        "id": "g8RLT1vKYsj0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# The dataset is primarily used for image segmentation, where the goal is to identify and delineate different structures (e.g., mitochondria or synapses) within the brain tissue.\n",
        "# The challenge is to train machine learning models (like neural networks) to perform this segmentation accurately.\n",
        "#\n",
        "\n",
        "model = load_model(\"Segmanation.keras\")\n",
        "\n",
        "\n",
        "# Load data function\n",
        "def load_data():\n",
        "  # Load the TIFF images\n",
        "  custom_img = tifffile.imread('/content/testing.tif')\n",
        "  custom_labels = tifffile.imread('/content/testing_groundtruth.tif')\n",
        "\n",
        "  # Normalize the images to [0, 1]\n",
        "  custom_img = custom_img.astype(np.float32) / np.max(train_images)\n",
        "  # Ensure labels are binary (0 or 1)\n",
        "  custom_labels = (custom_labels > 0).astype(np.float32)\n",
        "\n",
        "  # Add channel dimension for compatibility with Keras (depth, height, width, channels)\n",
        "  custom_img = np.expand_dims(custom_img, axis=-1)\n",
        "  custom_labels = np.expand_dims(custom_labels, axis=-1)\n",
        "\n",
        "  return custom_img, custom_labels\n",
        "\n",
        "# Load the data\n",
        "current_img, current_labels = load_data()\n",
        "\n",
        "# Resize images to (256, 256) and add a channel dimension for grayscale (1 channel)\n",
        "current_img = tf.image.resize(current_img, (256, 256))\n",
        "current_labels = tf.image.resize(current_labels, (256, 256))\n",
        "\n",
        "current_img = np.expand_dims(current_img, axis=-1)  # Adds the channel dimension\n",
        "\n",
        "# Ensure labels are clipped between 0 and 1\n",
        "current_labels = np.clip(current_labels, 0, 1)\n",
        "\n",
        "# Check if the shapes are now correct\n",
        "print(current_img.shape)  # Should be (num_samples, 256, 256, 1)\n",
        "print(current_labels.shape)   # Should be (num_samples, 256, 256, 1)\n",
        "\n",
        "# Predict on test images\n",
        "predicted_labels = model.predict(current_img)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "# Save each slice as a frame in a GIF\n",
        "frames = []\n",
        "for i in range(predicted_labels.shape[0]):  # Loop through the images in the batch\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(predicted_labels[i, :, :, 0], cmap='gray')  # Adjust the indices based on shape\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Save frame to a file-like object for creating the GIF\n",
        "    fig.canvas.draw()\n",
        "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
        "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "    frames.append(frame)\n",
        "    plt.close(fig)\n",
        "\n",
        "# Create a GIF\n",
        "gif_path = 'segmentation_resultsfinal2.gif'\n",
        "imageio.mimsave(gif_path, frames, fps=5)\n",
        "\n",
        "print(f\"GIF saved at: {gif_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO27RfG7dep6",
        "outputId": "d7b43084-ed50-40be-a441-a8b398f18a73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 256, 256, 1, 1)\n",
            "(165, 256, 256, 1)\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-156f08021aaa>:57: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use buffer_rgba instead.\n",
            "  frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF saved at: segmentation_resultsfinal2.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdNn--szd3pX"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}